<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MySQL详解&优化记录]]></title>
    <url>%2F2019%2F02%2F14%2FMysql%E4%BC%98%E5%8C%96%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[概述MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，目前属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件。MySQL是一种关系数据库管理系统，关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL所使用的 SQL 语言是用于访问数据库的最常用标准化语言。MySQL 软件采用了双授权政策，分为社区版和商业版，由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。 新特性 表和索引的分区 行级复制 MySQL 基群基于磁盘的数据支持 MySQL 集群复制 增强的全文本搜索函数 增强的信息模式(数据字典) 可插入的 API 服务器日志表 XML（标准通用标记语言的子集）/ XPath支持 实例管理器 表空间备份 mysql_upgrade 升级程序 内部任务/事件调度器 新的性能工具和选项如 mysqlslap DBMS数据库管理系统(DataBase Manage System)。 DQL 数据查询语言（Data Query Language, DQL）是SQL语言中，负责进行数据查询而不会对数据本身进行修改的语句，这是最基本的SQL语句。 DDL 数据定义语言（Data Definition Language，DDL）是SQL语言集中负责数据结构定义与数据库对象定义的语言，由CREATE、ALTER与DROP三个语法所组成，最早是由Codasyl（Conference on Data Systems Languages）数据模型开始，现在被纳入SQL指令中作为其中一个子集。 DML 数据操纵语言（Data Manipulation Language, DML）欧美地区的开发人员把这四种指令，以“CRUD”(分别为 Create, Read, Update, Delete英文四前缀字母缩略的术语)来称呼；而亚洲地区使用汉语的开发人员，或可能以四个汉字：增 查 改 删 来略称。 DCL 数据控制语言 (Data Control Language) 在SQL语言中，是一种可对数据访问权进行控制的指令，它可以控制特定用户账户对数据表、查看表、预存程序、用户自定义函数等数据库对象的控制权。由 GRANT 和 REVOKE 两个指令组成。 MVCCMVCC 是一种多版本并发控制机制，是通过保存数据在某个时间点的快照来实现的. 不同存储引擎的MVCC. 不同存储引擎的MVCC实现是不同的,典型的有乐观并发控制和悲观并发控制。 大多数的MYSQL事务型存储引擎,如InnoDB，Falcon以及PBXT都不使用一种简单的行锁机制.事实上,他们都和MVCC–多版本并发控制来一起使用. 众所周知,锁机制可以控制并发操作,但是其系统开销较大,而MVCC可以在大多数情况下代替行级锁,使用MVCC,能降低其系统开销. 事务隔离级别 事务是数据库系统区别于其他一切文件系统的重要特性之一 事务是一组具有原子性的SQL语句，或者一个独立的工作单元 mysql默认的事务隔离级别为 repeatable-read，可以使用如下命令查询：1select @@tx_isolation; 事务的基本要素（ACID） 1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。 2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。 3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。 4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。 事务的并发问题 1、脏读：未提交读(READ UNCOMMITED)，事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。 2、不可重复读：已提交读(READ COMMITED)符合隔离性的基本概念，事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。 3、可重复读：(REPEATABLE READ) InnoDB的默认隔离等级。事务进行时，其它所有事务对其不可见，即多次执行读，得到的结果是一样的！ 4、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。 事务隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否 数据库锁MySQL中锁主要作用是针对共享资源的并发访问以及用于实现事务的隔离性。 MySQL数据中常见的锁解读 乐观锁乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。乐观事务控制最早是由孔祥重（H.T.Kung）教授提出。 乐观并发控制多数用于数据争用不大、冲突较少的环境中，这种环境中，偶尔回滚事务的成本会低于读取数据时锁定数据的成本，因此可以获得比其他并发控制方法更高的吞吐量。 优缺点： 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。 悲观锁 悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作读某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。 悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 按使用性质划分 共享锁（Share Lock） S锁，也叫读锁，用于所有的只读数据操作。共享锁是非独占的，允许多个并发事务读取其锁定的资源。 多个事务可封锁同一个共享页； 任何事务都不能修改该页； 通常是该页被读取完毕，S锁立即被释放。 更新锁（Update Lock） U锁，在修改操作的初始化阶段用来锁定可能要被修改的资源，这样可以避免使用共享锁造成的死锁现象。因为当使用共享锁时，修改数据的操作分为两步： 首先获得一个共享锁，读取数据，然后将共享锁升级为排他锁，再执行修改操作。 这样如果有两个或多个事务同时对一个事务申请了共享锁，在修改数据时，这些事务都要将共享锁升级为排 他锁。这时，这些事务都不会释放共享锁，而是一直等待对方释放，这样就造成了死锁。 如果一个数据在修改前直接申请更新锁，在数据修改时再升级为排他锁，就可以避免死锁。 排他锁（Exclusive Lock） X锁，也叫写锁，表示对数据进行写操作。如果一个事务对对象加了排他锁，其他事务就不能再给它加任何锁了。（某个顾客把试衣间从里面反锁了，其他顾客想要使用这个试衣间，就只有等待锁从里面打开了。） 按作用范围划分 行锁 锁的作用范围是行级别。 表锁 锁的作用范围是整张表。数据库能够确定那些行需要锁的情况下使用行锁，如果不知道会影响哪些行的时候就会使用表锁。 页锁 对表中一组连续的行进行加锁。 性能比较 表锁：开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低 行锁：开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高 页锁：开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般 优缺点： 悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数据。 MySQL性能影响MySQL性能的几个因素： QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数。 TPS：是TransactionsPerSecond的缩写，也就是事务数/秒。它是软件测试结果的测量单位。 服务器硬件 服务器系统（系统参数优化） 磁盘IO 磁盘IO性能突然下降、大量消耗磁盘性能的计划任务。解决：更快磁盘设备、调整计划任务、做好磁盘维护。 网络延迟 存储引擎。 MyISAM： 不支持事务，表级锁。 InnoDB: 支持事务，支持行级锁，事务ACID。 数据库参数配置 数据库结构设计和SQL语句。（重点优化） 默认库解读 information_schema information_schema提供了访问数据库元数据的方式。(元数据是关于数据的数据，如数据库名或表名，列的数据类型，或访问权限等。有时用于表述该信息的其他术语包括“数据词典”和“系统目录”。) 换句换说，information_schema是一个信息数据库，它保存着关于MySQL服务器所维护的所有其他数据库的信息。(如数据库名，数据库的表，表栏的数据类型与访问权 限等。) 在INFORMATION_SCHEMA中，有几张只读表。它们实际上是视图，而不是基本表。 mysql mysql的核心数据库，类似于sql server中的master表，主要负责存储数据库的用户、权限设置、关键字等mysql自己需要使用的控制和管理信息。(常用的，在mysql.user表中修改root用户的密码)。 performance_schema 主要用于收集数据库服务器性能参数。并且库里表的存储引擎均为PERFORMANCE_SCHEMA，而用户是不能创建存储引擎为PERFORMANCE_SCHEMA的表。MySQL5.7默认是开启的。 sys Sys库所有的数据源来自：performance_schema。目标是把performance_schema的把复杂度降低，让DBA能更好的阅读这个库里的内容。让DBA更快的了解DB的运行情况。 体系结构 客户端 服务层 连接管理、查询缓存、查询解析、查询优化器 存储引擎 执行流程 存储引擎MySQL常见的存储引擎有InnoDB和MyISAM两种，其他NDBCluster、Merge、Memory等稍微了解即可。 InnoDB 在InnoDB中，如果只需要查找索引的列，就尽量不要加入其它的列，这样会提高查询效率。 InnoDB 使用 B+Tree 作为索引结构，叶节点直接存储的是完整的数据记录，索引的 key 是数据表的主键,因此 InnoDB 表数据文件本身就是主索引。 查看InnoDB数据存储 1show variables like 'innodb_file_per_table' 如果innodb_file_per_table 为 ON 将建立独立的表空间，文件为tablename.ibd； 如果innodb_file_per_table 为 OFF 将数据存储到系统的共享表空间，文件为ibdataX（X为从1开始的整数）； MySQL5.5默认系统表空间与MySQL5.6及以后默认独立表空间 1.系统表空间无法简单的收缩文件大小，造成空间浪费，并会产生大量的磁盘碎片。 2.独立表空间可以通过optimeze table 收缩系统文件，不需要重启服务器也不会影响对表的正常访问。 3.如果对多个表进行刷新时，实际上是顺序进行的，会产生IO瓶颈。 4 独立表空间可以同时向多个文件刷新数据。 5 强烈建立对Innodb 使用独立表空间，优化什么的更方便，可控。 特性：支持事务和行级锁（具体说明参考事务和锁） InnoDB的存储文件格式分为： .frm:表结构定义信息 .ibd:表数据和索引数据 MyISAM MyISAM存储引擎采用的是非聚簇索引，非聚簇索引的主索引和辅助索引几乎是一样的，只是主索引不允许重复，不允许空值，他们的叶子结点的key都存储指向键值对应的数据的物理地址。 非聚簇索引的数据表和索引表是分开存储的。 非聚簇索引中的数据是根据数据的插入顺序保存。因此非聚簇索引更适合单个数据的查询。插入顺序不受键值影响。 只有在MyISAM中才能使用FULLTEXT索引。 MyISAM 引擎默认使用 B+Tree 作为索引结构,叶节点的 data 域存放的是数据记录的地址。 MyISAM存储引擎的表在数据库中，每一个表都被存放为三个以表名命名的物理文件。首先肯定会有任何存储引擎都不可缺少的存放表结构定义信息的.frm文件，另外还有.MYD和.MYI文件，分别存放了表的数据（.MYD）和索引数据（.MYI）。每个表都有且仅有这样三个文件做为MyISAM存储类型的表的存储，也就是说不管这个表有多少个索引，都是存放在同一个.MYI文件中。 支持R-Tree索引、R-Tree索引、全文索引。 MyISAM的存储文件格式分为： .frm:表结构定义信息 .MYD:表的数据 .MYI:索引数据 InnoDB和MyISAM的区别 使用主索引的时候，更适合使用聚簇索引，因为聚簇索引只需要查找一次，而非聚簇索引在查到数据的地址后，还要进行一次I/O查找数据。 因为聚簇辅助索引存储的是主键的键值，因此可以在数据行移动或者页分裂的时候降低委会成本，因为这时不用维护辅助索引。但是辅助索引会占用更多的空间。 聚簇索引在插入新数据的时候比非聚簇索引慢很多，因为插入新数据时需要减压主键是否重复，这需要遍历主索引的所有叶节点，而非聚簇索引的叶节点保存的是数据地址，占用空间少，因此分布集中，查询的时候I/O更少，但聚簇索引的主索引中存储的是数据本身，数据占用空间大，分布范围更大，可能占用好多的扇区，因此需要更多次I/O才能遍历完毕。 Archive Archive非常适合存储大量的独立的，作为历史记录的数据。因为它们不经常被读取。Archive 拥有高效的插入速度，但其对查询的支持相对较差。 Memory Memory所有数据置于内存的存储引擎，拥有极高的插入，更新和查询效率。但是会占用和数据量成正比的内存空间。并且其内容会在 MySQL 重新启动时丢失 Merge Merge是将一定数量的 MyISAM 表联合而成一个整体，在超大规模数据存储时很有用。 CSV 逻辑上由逗号分割数据的存储引擎。它会在数据库子目录里为每个数据表创建一个 .csv 文件。这是一种普通文本文件，每个数据行占用一个文本行。CSV 存储引擎不支持索引。 BlackHole 黑洞引擎，写入的任何数据都会消失，一般用于记录 binlog 做复制的中继。 EXAMPLE EXAMPLE 存储引擎是一个不做任何事情的存根引擎。它的目的是作为 MySQL 源代码中的一个例子，用来演示如何开始编写一个新存储引擎。同样，它的主要兴趣是对开发者。EXAMPLE 存储引擎不支持编索引。 数据预热默认情况，仅仅有某条数据被读取一次，才会缓存在innodb_buffer_pool。所以，数据库刚刚启动，须要进行数据预热，将磁盘上的全部数据缓存到内存中。数据预热能够提高读取速度。对于InnoDB数据库，能够用下面方法，进行数据预热。 1.将下面脚本保存为 MakeSelectQueriesToLoad.sql 123456789101112131415161718192021222324252627SELECT DISTINCT CONCAT('SELECT ',ndxcollist,' FROM ',db,'.',tb, ' ORDER BY ',ndxcollist,';') SelectQueryToLoadCache FROM ( SELECT engine,table_schema db,table_name tb, index_name,GROUP_CONCAT(column_name ORDER BY seq_in_index) ndxcollist FROM ( SELECT B.engine,A.table_schema,A.table_name, A.index_name,A.column_name,A.seq_in_index FROM information_schema.statistics A INNER JOIN ( SELECT engine,table_schema,table_name FROM information_schema.tables WHERE engine='InnoDB' ) B USING (table_schema,table_name) WHERE B.table_schema NOT IN ('information_schema','mysql') ORDER BY table_schema,table_name,index_name,seq_in_index ) A GROUP BY table_schema,table_name,index_name ) AAORDER BY db,tb; 2.运行 1mysql -uroot -AN &lt; /root/MakeSelectQueriesToLoad.sql &gt; /root/SelectQueriesToLoad.sql 3.加入启动脚本到 my.cnfbashvim /etc/my.cnf [mysqld] init-file=/var/lib/mysql/upcache.sql1234567### MySQL执行线程**1、查看`MySQL`当前连接数**```bashshow full processlist; statistics 状态的线程，表示正在计算统计数据，以制定一个查询执行计划。 如果一个线程很长一段时间处于这种状态，可能是磁盘绑定的，即磁盘IO性能很差，说到底就是数据库服务器IO遇到问题了，可以通过增加 buffer_pool 来缓存更多的数据，或者提高服务器IO能力，可能磁盘在执行其他工作。 服务器IO状态会一直占用cpu，导致性能严重下降。 2、显示MySQL状态 1show status; Aborted_clients 由于客户没有正确关闭连接已经死掉，已经放弃的连接数量。 Aborted_connects 尝试已经失败的MySQL服务器的连接的次数。 Connections 试图连接MySQL服务器的次数。 Created_tmp_tables 当执行语句时，已经被创造了的隐含临时表的数量。 Delayed_insert_threads 正在使用的延迟插入处理器线程的数量。 Open_tables 打开表的数量。 Open_files 打开文件的数量。 Open_streams 打开流的数量(主要用于日志记载） Opened_tables 已经打开的表的数量。 Questions 发往服务器的查询的数量。 Slow_queries 要花超过long_query_time时间的查询数量。 Threads_connected 当前打开的连接的数量。 Threads_running 不在睡眠的线程数量。 Uptime 服务器工作了多少秒。 3、终止正在执行的MySQL线程 1kill id; 杀死耗时或者长时间处于Sending to Client状态的慢sql。 减少磁盘绑定： 1) 扩大innodb_buffer_pool_size的缓冲池大小。如果你用Innodb然后，当表数据缓存在InnoDB缓冲池中时，可以通过查询一次又一次地处理表数据，而不需要任何磁盘I/O。这个内存区域非常重要，以至于繁忙的数据库通常指定的大小约为物理内存量的80%。 2) 在GNU/Linux和Unix的某些版本中，使用Unixfsync()调用(InnoDB默认使用)将文件刷新到磁盘，类似的方法非常慢。如果数据库写入性能是一个问题，则使用INNODB_FLUSH_Method参数设置为O_DSYNC进行基准测试。 3) 扩大innodb_buffer_pool_size的数据库日志缓冲区大小-设置分配给存储InnoDB预写日志条目的缓冲区的内存量。对于大型事务，可以将日志加载到日志缓冲区中，而不是将日志写入磁盘上的日志文件，直到日志缓冲区在每次事务提交时被刷新为止。如果您在运行时在显示nodb状态输出中看到大型日志I/O，则可能需要为innodb_log_buffer_size参数设置更大的值，以保存磁盘I/O。 4) 增加用于缓存表和查询的内存-检查表和查询的缓存命中率，检查并增加这些MySQL变量：query_cache_size, query_cache_limit, query_cache_min_res_unit, tmp_table_size, join_buffer_size , sort_buffer_size等等。 5) 确保对服务器上的所有表都应用了适当的索引，并使用正确的数据类型。 建议：查看当前io性能状态，例如iostat SQL调优 SQL执行顺序 12345678910FROM &lt;left_table&gt;ON &lt;join_condition&gt;&lt;join_type&gt; JOIN &lt;right_table&gt;WHERE &lt;where_condition&gt;GROUP BY &lt;group_by_list&gt;HAVING &lt;having_condition&gt;SELECTDISTINCT &lt;select_list&gt;ORDER BY &lt;order_by_condition&gt;LIMIT &lt;limit_number&gt; SQL优化 禁用select * 使用select count(*) 统计行数 尽量少运算 尽量避免全表扫描，如果可以，在过滤列建立索引 尽量避免在where子句对字段进行null判断 尽量避免在where子句使用!= 或者&lt;&gt; 尽量避免在where子句使用or连接 尽量避免对字段进行表达式计算 尽量避免对字段进行函数操作 尽量避免使用不是复合索引的前缀列进行过滤连接 尽量少排序，如果可以，建立索引 尽量少join 尽量用join代替子查询 尽量避免在where子句中使用in,not in或者having，使用exists,not exists代替 尽量避免两端模糊匹配 like %*% 尽量用union all代替union 尽量早过滤 避免类型转换 尽量批量insert 优先优化高并发sql，而不是频率低的大sql 尽可能对每一条sql进行explain 尽可能从全局出发 Order By优化 filesort优化算法. 在mysql version()&lt;4.1之前，优化器采用的是filesort第一种优化算法，先提取键值和指针，排序后再去提取数据，前后要搜索数据两次，第一次若能使用索引则使用，第二次是随机读(当然不同引擎也不同)。mysql version()&gt;=4.1,更新了一个新算法，就是在第一次读的时候也把selcet的列也读出来，然后在sort_buffer_size中排序(不够大则建临时表保存排序顺序)，这算法只需要一次读取数据。所以有这个广为人传的一个优化方法，那就是增大sort_buffer_size。Filesort第二种算法要用到更的空间，sort_buffer_size不够大反而会影响速度，所以mysql开发团队定了个变量max_length_for_sort_data，当算法中读出来的需要列的数据的大小超过该变量的值才使用，所以一般性能分析的时候会尝试把max_length_for_sort_data改小。 单独order by 用不了索引，索引考虑加where 或加limit。 当order by 和 group by无法使用索引时，增大max_length_for_sort_data参数设置和增大sort_buffer_size参数的设置。 索引命中&amp;失效索引是一种特殊的文件（InnoDB 数据表上的索引是表空间的一个组成部分），它们包含着对数据表里所有记录的引用指针。索引不是万能的，索引可以加快数据检索操作，但会使数据修改操作变慢。每修改数据记录，索引就必须刷新一次。为了在某种程度上弥补这一缺陷，许多 SQL 命令都有一个 DELAY_KEY_WRITE 项。这个选项的作用是暂时制止 MySQL 在该命令每插入一条新记录和每修改一条现有之后立刻对索引进行刷新，对索引的刷新将等到全部记录插入/修改完毕之后再进行。在需要把许多新记录插入某个数据表的场合，DELAY_KEY_WRITE 选项的作用将非常明显。另外，索引还会在硬盘上占用相当大的空间。因此应该只为最经常查询和最经常排序的数据列建立索引。注意，如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。 数据库表的索引从数据存储方式上可以分为聚簇索引和非聚簇索引（又叫二级索引）两种。 聚簇索引 Innodb的聚簇索引在同一个B-Tree中保存了索引列和具体的数据，在聚簇索引中，实际的数据保存在叶子页中，中间的节点页保存指向下一层页面的指针。“聚簇”的意思是数据行被按照一定顺序一个个紧密地排列在一起存储。一个表只能有一个聚簇索引，因为在一个表中数据的存放方式只有一种。 聚簇索引的优点 聚簇索引将索引和数据行保存在同一个B-Tree中，查询通过聚簇索引可以直接获取数据，相比非聚簇索引需要 第二次查询（非覆盖索引的情况下）效率要高。 聚簇索引对于范围查询的效率很高，因为其数据是按照大小排列的， 聚簇索引的缺点 聚簇索引的更新代价比较高，如果更新了行的聚簇索引列，就需要将数据移动到相应的位置。这可能因为要插 入的页已满而导致“页分裂”。 插入速度严重依赖于插入顺序，按照主键进行插入的速度是加载数据到Innodb中的最快方式。如果不是按照主 键插入，最好在加载完成后使用OPTIMIZE TABLE命令重新组织一下表。 聚簇索引在插入新行和更新主键时，可能导致“页分裂”问题。 聚簇索引可能导致全表扫描速度变慢，因为可能需要加载物理上相隔较远的页到内存中（需要耗时的磁盘寻道操作）。 非聚簇索引 非聚簇索引，又叫二级索引。二级索引的叶子节点中保存的不是指向行的物理指针，而是行的主键值。当通过二级索引查找行，存储引擎需要在二级索引中找到相应的叶子节点，获得行的主键值，然后使用主键去聚簇索引中查找数据行，这需要两次B-Tree查找。 普通索引 普通索引（由关键字 KEY 或 INDEX 定义的索引）的任务是加快对数据的访问速度。因此，应该只为那些最经常出现查询条件（WHERE column =）或排序条件（ORDER BY column）中的数据列创建索引。只要有可能，就应该选择一个数据最整齐、最紧凑的数据列（如一个整数类型的数据列）来创建索引。 唯一索引 与”普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。 主键索引 主键索引是一种特殊的唯一索引，不允许有空值，这个索引就是所谓的“主索引”。主索引区别是：前者在定义时使用的关键字是 PRIMARY 而不是 UNIQUE。 BTree索引 叶子结点指针都为null；非叶子结点的key都是[key,data]二元组，其中key表示作为索引的键，data为键值所在行的数据；BTree的结构下，就可以使用二分查找的查找方式，查找复杂度为h*log(n)，一般来说树的高度是很小的，一般为3左右，因此BTree是一个非常高效的查找结构。 B+Tree索引 B+Tree是BTree的一个变种，设d为树的度数，h为树的高度，B+Tree和BTree的不同主要在于：B+Tree中的非叶子结点不存储数据，只存储键值；B+Tree的叶子结点没有指针，所有键值都会出现在叶子结点上，且key存储的键值对应的数据的物理地址； 组合索引 遵循最左前缀原则，索引可以覆盖多个数据列，如像 INDEX (columnA, columnB) 索引。这种索引的特点是 MySQL 可以有选择地使用一个这样的索引。如果查询操作只需要用到 columnA 数据列上的一个索引，就可以使用复合索引 INDEX(columnA, columnB)。不过，这种用法仅适用于在复合索引中排列在前的数据列组合。比如说，INDEX (A，B，C) 可以当做 A 或 (A,B) 的索引来使用，但不能当做 B、C 或 (B,C) 的索引来使用。 全文索引 仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时好空间。 索引失效 关联字段类型不同索引字段使用函数表达式like %AAAis null GROUP BY 的索引应用 1、查询字段必须和后面GROUP BY 一致select TeamID from competeinfo where TeamID &gt;10 group by TeamID。这里就是通过TeamID 来查找。完成group by 。 2、联合索引的应用，切记注意GROUP BY 顺序，Where 条件和GROUP BY 字段得是一个索引里面的这个表CompeteID,TeamID建立联合索引1）select TeamID from competeinfo where TeamID &gt;10 and CompeteID &gt; 100020 group by CompeteID这个查询用到了CompeteID,TeamID联合索引2）select TeamID from competeinfo where TeamID &gt;10 and CompeteID &gt; 100020 group by TeamID这样的话查询group by中就没有用到索引了 下面是总结的是联合索引的使用： Index（Name，Age）表示在Name，Age两列上建立联合索引 如果where name=&apos;pp&apos; 能使用索引 where age=25时不能使用索引 where name=&apos;pp&apos; and age&gt;25 能使用索引 where name =&apos;pp&apos; order by age 能使用索引 where name&gt;&apos;pp&apos; order by age 不能使用索引 where name&gt;&apos;pp&apos; order by name,age 能使用索引 order by name asc age desc 将不能使用索引！ 主从配置文件MySQL主从复制时时同步，是在开启log-bin日志文件的基础上，开始的时候记录主库的Position，作为从库同步的开始节点,所以主从库都必须开启log-bin日志，恢复数据也是根据此文件来操作要恢复的节点。 查看主库Position： 主库配置12GRANT replication slave ON *.* TO 'root'@'10.10.253.%' identified by '123456';flush privileges; 主库配置文件123456789101112131415161718#安装目录basedir = /usr/local/mysql#数据目录datadir = /usr/local/mysql/data#端口port = 3306#socket 路径socket = /var/lib/mysql/mysql.sock#log-bin日志文件log-bin=mysql-bin-1#serverId，一般为ip的最后一段，避免重复server_id=119#开启查询缓存explicit_defaults_for_timestamp=true#设置最新日志保留时间，节省磁盘空间expire_logs_days = 10#sql_mode模式，定义了mysql应该支持的sql语法，数据校验等sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES sql_mode常见的sql_mode有以下几种 NO_ENGINE_SUBSTITUTION模式 如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常。STRICT_TRANS_TABLES模式 严格模式，进行数据的严格校验，错误数据不能插入，报error错误。在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制。ANSI模式 宽松模式，对插入数据进行校验，如果不符合定义类型或长度，对数据类型调整或截断保存，报warning警告。 TRADITIONAL模式 严格模式，当向mysql数据库插入数据时，进行数据的严格校验，保证错误数据不能插入，报error错误。用于事物时，会进行事物的回滚。 ONLY_FULL_GROUP_BY模式 出现在select语句、HAVING条件和ORDER BY语句中的列，必须是GROUP BY的列或者依赖于GROUP BY列的函数列。NO_AUTO_VALUE_ON_ZERO模式 该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。如果用户希望插入的值为0，而该列又是自增长的，那么这个选项就有用了。NO_ZERO_IN_DATE模式 这个模式影响了是否允许日期中的月份和日包含0。如果开启此模式，2016-01-00是不允许的，但是0000-02-01是允许的。它实际的行为受到 strict mode是否开启的影响1。NO_AUTO_CREATE_USER模式 禁止GRANT创建密码为空的用户ANSI_QUOTES模式 启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符。 从库设置 根据查看到的主库status，记录log-bin和position。 12change master to master_host='192.168.80.9',master_user='root',master_password='123456',master_log_file='mysql-bin-1.000003',master_log_pos=13177757 ; 从库配置文件123456789101112131415161718#安装目录basedir = /usr/local/mysql#数据目录datadir = /usr/local/mysql/data#端口port = 3306#socket 路径socket = /var/lib/mysql/mysql.sock#log-bin日志文件log-bin=mysql-bin-1#serverId，一般为ip的最后一段，避免重复server_id=119#开启查询缓存explicit_defaults_for_timestamp=true#设置需要同步主库的DBreplicate-do-db=hsg_oa#设置不需要同步主库的DBreplicate-ignore-db=information_schema,mysql,performance_schema,sys 删除主从库data下面的auto.cnf，会导致主从库同步节点不一致问题。 默认配置参数 sort_buffer_size 定义了每个线程排序缓存区的大小，MySQL在有查询、需要做排序操作时才会为每个缓冲区分配内存（直接分配该参数的全部内存）； join_buffer_size 定义了每个线程所使用的连接缓冲区的大小，如果一个查询关联了多张表，MySQL会为每张表分配一个连接缓冲，导致一个查询产生了多个连接缓冲； read_buffer_size 定义了当对一张MyISAM进行全表扫描时所分配读缓冲池大小，MySQL有查询需要时会为其分配内存，其必须是4k的倍数； read_rnd_buffer_size 索引缓冲区大小，MySQL有查询需要时会为其分配内存，只会分配需要的大小。 注意：以上四个参数是为一个线程分配的，如果有100个连接，那么需要×100。 MySQL数据库实例： MySQL是单进程多线程（而oracle是多进程），也就是说MySQL实例在系统上表现就是一个服务进程，即进程； MySQL实例是线程和内存组成，实例才是真正用于操作数据库文件的； 一般情况下一个实例操作一个或多个数据库；集群情况下多个实例操作一个或多个数据库。 如何为缓存池分配内存： Innodb_buffer_pool_size，定义了Innodb所使用缓存池的大小，对其性能十分重要，必须足够大，但是过大时，使得Innodb 关闭时候需要更多时间把脏页从缓冲池中刷新到磁盘中； 总内存-（每个线程所需要的内存*连接数）-系统保留内存 key_buffer_size，定义了MyISAM所使用的缓存池的大小，由于数据是依赖存储操作系统缓存的，所以要为操作系统预留更大的内存空间； select sum(index_length) from information_schema.talbes where engine=’myisam’ 注意：即使开发使用的表全部是Innodb表，也要为MyISAM预留内存，因为MySQL系统使用的表仍然是MyISAM表。max_connections 控制允许的最大连接数，一般2000更大。不要使用外键约束保证数据的完整性。 日志事务性存储引擎及主要日志类型：Redo Log 、 Undo Log 和 general log Redo Log：实现事务的持久性(已提交的事务)。 Undo Log：未提交的事务，独立于表空间，需要随机访问，可以存储在高性能io设备上 general log：mysql将对DB的所有操作都可以记录在general log中，我们可以在线开启也可以通过修改初始化参数开启，调试用。 主要说明一下general log的使用： 在线打开和关闭12set global general_log=on;set global general_log=off; 通过下面sql方法可以查看mysql.general_log表的存储引擎是什么show table status from mysql where name=’general_log’; 这个表的缺省存储引擎是CSV，我们可以将该存储引擎修改成myisam来达到更好的性能。1234567891011mysql&gt; alter table mysql.general_log engine=myisam;1580 - You cannot 'ALTER' a log table if logging is enabledmysql&gt; set global general_log=off;Query OK, 0 rows affectedmysql&gt; alter table mysql.general_log engine=myisam;Query OK, 11 rows affectedRecords: 11 Duplicates: 0 Warnings: 0mysql&gt; set global general_log=on;Query OK, 0 rows affected 记录general log可以很好的监控当前数据库中的所有操作，可以选择在忙时打开，这样就可以对性能进行优化。但general log比较消耗系统性能，生产系统不建议打开 视图视图概述 视图本身是一个虚拟表，不存放任何数据，查询视图的数据集由其他表生成。MySQL底层通过两种算法来实现视图：临时表算法（TEMPTABLE）和合并算法（MERGE）。 临时表算法就是将SELECT语句的结果存放到临时表中，当需要访问视图的时候，直接访问这个临时表即可。 相比于其它关系型数据库的视图，MySQL的视图在功能上会弱很多，比如ORACLE和MS SQL SERVER都支持物化视图。物化视图是指将视图结果数据存放在一个可以查询的表中，并定期从原始表中刷新数据到这张表中，这张表和普通物理表一样，可以创建索引、主键约束等等，性能相比于临时表会有质的提升。但遗憾的是MySQL目前并不支持物化视图，当然MySQL也不支持在视图中创建索引。 视图的实现算法是视图本身的属性决定的，跟作用在视图上的SQL没有任何关系。一般来说，只要原表记录和视图中的记录无法建立一一映射的关系时，MySQL都将使用临时表算法来实现视图。比如创建视图的SQL中包含GROUP BY、DISTINCT、UNION、聚合函数、子查询的时候，视图都将采用临时表算法（这些规则在以后的版本中，可能会发生改变，具体请参考官方手册） 视图用途 首先视图可以简化应用上层的操作，让应用更专注于其所关心的数据。其次，视图能够对敏感数据提供安全保护，比如：对不同的用户定义不同的视图，可以使敏感数据不出现在不应该看到这些数据的用户视图上；也可以使用视图实现基于列的权限控制，而不需要真正的在数据库中创建列权限。再者，视图可以方便系统运维，比如：在重构schema的时候使用视图，使得在修改视图底层表结构的时候，应用代码还可以继续运行不报错。 Explain&amp;Profiling Explain 使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是 如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈。 使用方式：Explain+SQL语句 详细参数说明参见MySQL 性能优化神器 Explain 使用分析，里面写的很有特点。 Profiling 开启profiling设置 查看profiling信息状态: on为开启，off关闭 12show variables like '%profiling%'; set profiling=1; 执行SQL查询 12SELECT * FROM oa_sign_in ; show profiles; 1show profile cpu,block io for query 168; 参考文献 statistics State in MySQL Processlist List of background operations performed by MySQL InnoDB Main thread processlist中哪些状态要引起关注 是什么导致MySQL数据库服务器磁盘I/O高？ table_open_cache 与 table_definition_cache 对MySQL(内存)的影响 8.5.8 Optimizing InnoDB Disk I/O MySQL的四种事务隔离级别 轻松理解MYSQL MVCC 实现机制 MySQL性能管理及架构设计 MySQL索引背后的数据结构及算法原理]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>优化</tag>
        <tag>sql</tag>
        <tag>主从配置</tag>
        <tag>事务</tag>
        <tag>索引</tag>
        <tag>存储引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins自动化安装部署-权限配置（三）]]></title>
    <url>%2F2019%2F02%2F10%2FJenkins%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-%E6%9D%83%E9%99%90%E9%85%8D%E7%BD%AE%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[权限配置Jenkins的权限配置很重要，尤其是项目团队比较多的时候，可以防止一些奇葩的程序员进行误操作，一般情况下，只有A项目组的人才可以构建和操作A项目的权限，其他项目组是看不到的。因此合理的配置Jenkins权限可以使其发挥更大的功效，避免操作额外的麻烦。 系统管理里面选择Manage and Assign Roles，来配置Jenkins的相关权限。 Manage Roles ：包括全局角色和项目角色 Assign Roles ：分配全局和项目角色 分配全局角色 分配项目角色 配置完成只有拥有Jenkins分配到权限的人才可以构建项目操作。 构建日志 项目构建历史里点击控制台输出即可查看当前项目构建的过程、更新了哪些文件以及服务器部署过程，便于快速的定位问题以及代码错误的文件名称。 在当前构建系统中可以查看到所有依赖的环境变量。 变更记录可以快速定位到某个开发提交了哪个错误文件导致的部署失败问题。 部署问题Tomcat应用更新时，把新的WAR包放到webapps目录下，Tomcat就会自动把原来的同名webapp删除，并把WAR包解压，运行新的 webapp。 有时候Tomcat并不能把旧的webapp完全删除，通常会留下WEB-INF/lib下的某个jar包，必须关闭Tomcat才能删除，这就导致自动部署失败。解决方法：查看tomcate/conf/context.xml中的 context节点，元素中增加一个属性antiResourceLocking=”true” antiJARLocking=”true”，默认是”false”。这样就可以热部署了。这两个参数就是配置Tomcat的资源锁定和Jar包锁定策略。 延伸问题，解压后的原context.xml文件中的context节点默认有两个属性：antiResourceLocking=”true” antiJARLocking=”true”，即Tomcat的资源锁定和Jar包锁定策略。 当antiResourceLocking=”true”时，tomcat每次启动时都会在temp目录下生成相应工程的临时文件，并把这些文件锁定，所以即使修改文件后，webapps文件夹下的修改时间会更新，但是temp文件夹下的修改时间是启动tomcate之前的修改时间。而用户在浏览器访问的资源却是temp下的，不是webapps下的。所以最终导致用户修改的效果无法在浏览器中看到。当antiResourceLocking=“false”后，temp目录下就不会生成临时文件了，这是用户访问的就是webapps下的资源了。 解决方法：查看tomcate/conf/context.xml中的 context节点。如果有antiResourceLocking这个属性，应该把他的值设为false。通过设置reloadable=”true” 属性，该属性主要用于自动部署java文件的修改。 1&lt;Context antiResourceLocking="true"&gt; 注：以上问题是直接通过tomcat内部账号连接部署的时候会发生的问题，如果直接通过scp文件上传打包到服务器不会出现上述问题。 如果部署后出现缓存问题，修改的配置文件等没有生效，手动删除Jenkins工作空间的war文件。 注：如果配置文件进行修改后，而已经部署到Jenkins的workspace中的war没有清理，继续构建的话，Jenkins会默认保留已构建的war，而不会将最新的文件关联到nexus中。 在jenkins中配置自动更新部署项目时，如果采取用execute shell启动/关闭tomcat，会发现可以进行关闭tomcat，但是无法启动tomcat，虽然构建会显示执行成功，但是查看进程，tomcat是没有启动的。这是因为Jenkins默认会在Build结束后Kill掉所有的衍生进程。需要进行以下配置，才能避免此类情况发生。 在启动jenkins 的时候禁止jenkins杀死衍生进程 修改/etc/sysconfig/jenkins配置，在JENKINS_JAVA_OPTIONS中加入-Dhudson.util.ProcessTree.disable=true。需要重启jenkins生效 此方法配置一次后，所有的job都无需设置BUILD_ID，就能够防止jenkins杀死启动的tomcat进]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>权限</tag>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins自动化安装部署-环境配置（二）]]></title>
    <url>%2F2019%2F02%2F10%2FJenkins%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[经过上述安装步骤，Jenkins已经成功安装到所在服务器中，下面通过访问地址进入web页面操作。 打开浏览器输出：http://服务器IP地址:8888/ 打开url会出现一个配置Jenkins的登录密码的界面，设置一个密码，继续进入如下面界，选择建议安装的插件，进行安装，等待安装完毕。 安装成功之后，进入Jenkins的主页面，开始新建job，也就是所谓的项目名，Jenkins中的项目名字相当于实际项目的逻辑名称，与之对应存储在jenkins的workspaces下。 Global Tool Configuration 在系统管理-全局环境配置，可以配置系统所需要的JDK、ANT、GIT、MAVEN、GRADLE、DOCKER等环境变量。 其次在项目配置中的源码管理里选择当前项目的svn资源库相关配置。以便部署项目的时候直接会从SVN服务器更新编译到本地。 注：一定要加@HEAD是把你本机工作区的版本更新到服务器上最新版本，这样可以避免造成文件冲突导致的文件不可用问题。 在构建中选择方式：Invoke Ant，并选择之前配置的ant版本，此处不能为default。 可以通过编辑视图来添加相关文档说明，也可以复制启动Banner直接到视图里。 配置完成之后在项目列表就可以针对当前项目进行构建自动化部署操作。 至此基本环境配置和项目配置就结束了，开始配置并分配用户权限以及项目开发人员的访问权限。]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Jenkins自动化安装部署-安装配置（一）]]></title>
    <url>%2F2019%2F02%2F10%2FJenkins%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[Jenkins概述Jenkins是一个独立的开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。前身是Hudson是一个可扩展的持续集成引擎。可用于自动化各种任务，如构建，测试和部署软件。Jenkins可以通过本机系统包Docker安装，甚至可以通过安装Java Runtime Environment的任何机器独立运行。 Jenkins特点 开源免费; 跨平台，支持所有的平台; master/slave支持分布式的build; web形式的可视化的管理页面; 安装配置超级简单; tips及时快速的帮助; 已有的200多个插件 系统要求 环境 说明 配置环境 JDK JDK1.5以上 JDK1.7 硬盘 无最低要求、根据实际项目大小适当即可。 80G 操作系统 Jenkins可以安装到主流的所有操作系统。 CentOS Java容器 WAR文件可以在支持 Servlet2.4/JSP2.0或更高版本的容器中运行 独立安装 代码库 支持SVN或者GIT等同步插件 （示例svn） svn 编译打包 支持Maven或ANT来自动构建（示例ant） ant 需求概述由于项目架构是SpringMVC，并没有使用Maven来构建，所以本文安装的Jenkins基于Ant环境构建发布（也可以使用Maven），配置比较方便。 Ant安装1[root@localhost jenkins]# vi /etc/profile 在最后添加 123ANT_HOME=/usr/local/apache-ant-1.8.4PATH=$ANT_HOME/bin:$PATHexport ANT_HOME 完整的配置如下 123456789JAVA_HOME=/usr/local/jdk7JRE_HOME=/usr/local/jdk7/jreJENKINS_HOME=/var/lib/jenkinsMAVEN_HOME=/usr/local/apache-maven-3.5.0ANT_HOME=/usr/local/apache-ant-1.8.4PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$MAVEN_HOME/bin:$ANT_HOME/bin:$PATHCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH MAVEN_HOME ANT_HOME CLASSPATH JENKINS_HOMEexport LD_LIBRARY_PATH=/usr/apr/lib 注意：ANT的1.9到1.10版本均由jdk1.8版本编译支持，如果用的是jdk1.7，要下载ANT1.8版本。如果是远程进行ant构建需要下载一个jar包，Ant提供的Sshexec和scp任务，由$ANT_HOME/lib/ant-jsch.jar提供支持，但是同样你也要在http://www.jcraft.com/jsch/index.html下载一个依赖包jsch-0.1.24.jar(文件名因版本而不同)，jsch同样也是http://www.sourceforge.net下的一个项目。你需要把下载的jsch-0.1.24拷贝到$ANT_HOME/lib下 Jenkins安装支持war和本地安装两种方式（本文主要说明第二种方式） Jenkins下载地址1https://jenkins.io/index.html 默认情况下，最新版本和长期支持版本可供下载。过去的版本也可以下载。单击下载部分的长期支持版本选项。 Jenkins两种安装方式 Jenkins的war包下载后发布到Tomcat服务器的Webapps下即可配（比较简单） 用于Jenkins的RedHat Linux RPM软件包(第二种方式) 使用Jenkins官网提供的源下载Jenkins，服务器上面执行下面命令： 123[root@localhost jenkins]# sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo[root@localhost jenkins]# sudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key[root@localhost jenkins]# sudo yum install jenkins 启动Jenkins 1[root@localhost jenkins]# service jenkins start/stop/restart jenkins的默认设置： Jenkins会随系统启动而启动。详情参照/etc/init.d/jenkins Jenkins会创建一个用户叫做jenkins, 如果你修改了user，则要修修改所属者：/var/log/jenkins,/var/lib/jenkins,/var/cache/jenkins 如果遇到问题，查看日志/var/log/jenkins/jenkins.log 配置文件/etc/sysconfig/jenkins 默认启用8080 （本文使用的是8888） 1[root@localhost jenkins]# vi /etc/sysconfig/jenkins 修改如下几个地方：1、JENKINS_USER=”root” 当前用户执行权限。2、JENKINS_JAVA_OPTIONS=”-Dhudson.util.ProcessTree.disable=true” 此处必须要改，防止在启动jenkins 的时候jenkins自动杀死衍生进程，导致服务器始终无法正常启动。3、JENKINS_PORT=”8888” 为了避免和Tomcat端口冲突，修改自己的端口。 安装后直接访问地址：1http://服务器IP地址:8888/]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql自动安装脚本]]></title>
    <url>%2F2019%2F02%2F10%2FMysql%E8%87%AA%E5%8A%A8%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[执行过程由于频繁安装mysql添加用户配置权限以及编译初始化过程基本一致，所以可以直接编写shell文件来自动执行重复的工作。 MySQL脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#!/bin/bash# 脚本 ：Mysql自动安装配置脚本# 说明 ：安装 mysql-5.6.32-linux-glibc2.5-x86_64.tar.gz on # 环境 ：Centos# 作者 ：Jackie.Yang# 编写日期：2016.09.20# 备份系统文件mv /etc/my.cnf /etc/my.cnf.bakcd /usr/local/cp ./e/my.cnf /etc/echo 解压缩...tar -zxvf mysql-5.6.32-linux-glibc2.5-x86_64.tar.gzsleep 15secho 解压完毕，进程等待...#修改安装名称mv mysql-5.6.32-linux-glibc2.5-x86_64 mysql#进去mysql根目录cd mysqlecho 添加用户groupadd mysqluseradd -g mysql mysqlecho 修改mysql所属用户组chown -R mysql:mysql /usr/local/mysqlecho 开始执行mysql安装。。。# mysql5.7之前版本初始化命令./scripts/mysql_install_db --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --user=mysql#mysql5.7的初始化命令# ./bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/dataecho 安装等待。。。sleep 15srm my.cnfcp ../m/my.cnf .chown -R mysql:mysql /usr/local/mysql/my.cnfcp support-files/mysql.server /etc/init.d/mysqldchmod +x /etc/init.d/mysqld#echo 添加mysql到系统服务#chkconfig --add mysqld #echo 添加mysql随机启动 #chkconfig mysqld oncd bin#service mysqld start | awk '&#123;print $3&#125;'service mysqld startecho 启动服务中...sleep 5s#判断字符串是否相等service mysqld start | awk '&#123;if("SUCCESS!"== $3) print "Mysql数据库启动成功！" &#125;' ln -s /var/lib/mysql/mysql.sock /tmp/mysql.sockecho 初始化数据库配置...# 5.7数据会生成临时密码：如：XAcLpcVsd9/.；# 修改密码#SET PASSWORD = PASSWORD('123456');./mysql -uroot -e "use mysqlupdate user set password=password('123456') where user='root';GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;flush privileges;quit"echo 配置成功，数据库用户：root； 密码：123456；exit;#service mysqld start | awk '&#123;if("SUCCESS!" != $3) print "Mysql数据库启动失败！" &#125;' 注：mysql5.7之前版本初始化配置表命令./scripts/mysql_install_db，mysql5.7的mysql_install_db命令是在bin目录下，并且建议用mysqld –initialize命令来执行初始化，此脚本针对Mysql5.6及以下版本，5.7等高版本需替换对应版本的初始化脚本。 配置文件 复制修改好的my.cnf到 /etc/下，内容如下： 1234567891011121314151617[mysqld] socket=/tmp/mysql.sock user=mysql basedir = /usr/local/mysql datadir = /usr/local/mysql/data port = 3306 server_id = 121 log_bin = mysql_bin wait_timeout=31536000 interactive_timeout=31536000# Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2M sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tengine安装和使用]]></title>
    <url>%2F2019%2F02%2F09%2FTengine%2F</url>
    <content type="text"><![CDATA[Tengine简介Tengine 作为淘宝Web服务器，是基于nginx的进行了订制开发和扩展，也解决了Nginx中upstream无法检查代理后端存活等众多不灵活的问题，本人正是由于此需求了解到了Tengine，并且完成了安装测试调试等一系列问题，最终部署生产应用。 Tengine发展Tengine的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的Web平台。从2011年12月开始，Tengine成为一个开源项目。现在，它由Tengine团队开发和维护。Tengine团队的核心成员来自于淘宝、搜狗等互联网企业。 Tengine功能 继承Nginx-1.6.2的所有特性，兼容Nginx的配置； 动态模块加载（DSO）支持。加入一个模块不再需要重新编译整个Tengine； 支持SO_REUSEPORT选项，建连性能提升为官方nginx的三倍； 支持SPDY v3协议，自动检测同一端口的SPDY请求和HTTP请求； 流式上传到HTTP后端服务器或FastCGI服务器，大量减少机器的I/O压力； 更加强大的负载均衡能力，包括一致性hash模块、会话保持模块，还可以对后端的服务器进行主动健康检查，根据服务器状态自动上线下线，以及动态解析upstream中出现的域名； 输入过滤器机制支持。通过使用这种机制Web应用防火墙的编写更为方便； 支持设置proxy、memcached、fastcgi、scgi、uwsgi在后端失败时的重试次数； 动态脚本语言Lua支持。扩展功能非常高效简单； 支持管道（pipe）和syslog（本地和远端）形式的日志以及日志抽样； 支持按指定关键字(域名，url等)收集Tengine运行状态； 组合多个CSS、JavaScript文件的访问请求变成一个请求； 自动去除空白字符和注释从而减小页面的体积 自动根据CPU数目设置进程个数和绑定CPU亲缘性； 监控系统的负载和资源占用从而对系统进行保护； 显示对运维人员更友好的出错信息，便于定位出错机器； 更强大的防攻击（访问速度限制）模块； 更方便的命令行参数，如列出编译的模块列表、支持的指令等； 可以根据访问文件类型设置过期时间； Tengine下载地址 下载地址：http://tengine.taobao.org/download.html 也可以通过wget直接下载到指定服务器： wget http://tengine.taobao.org/download/tengine-2.1.0.tar.gz 本人使用的是tengine版本2.1.0，相对来说比较稳定。 Tengine环境依赖由于Tengine安装需要使用源代码自行编译，所以在安装前需要安装必要的编译工具： 1、PCRE PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx rewrite依赖于PCRE库，所以在安装Tengine前一定要先安装PCRE。 123456cd /usr/local/ wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gz tar -zxvf pcre-8.42.tar.gz cd pcre-8.42 ./configure --prefix=/usr/local/pcre make &amp;&amp; make install 2、Zlib Zlib是提供资料压缩之用的函式库，当Tengine想启用GZIP压缩的时候就需要使用到Zlib 123456cd /usr/local/ wget http://zlib.net/zlib-1.2.11.tar.gz tar zxvf zlib-1.2.11.tar.gz cd zlib-1.2.11 ./configure --prefix=/usr/local/zlib make &amp;&amp; make install 3、jemalloc jemalloc是一个很好的内存管理工具，使用jemalloc可以更好的优化Tengine的内存管理。 123456cd /usr/local/ wget https://github.com/jemalloc/jemalloc/releases/download/5.0.1/jemalloc-5.0.1.tar.gz tar -zxvf jemalloc-5.0.1.tar.gz cd jemalloc-5.0.1 ./configure --prefix=/usr/local/jemalloc make &amp;&amp; make install 4、OpenSSL OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。安装OpenSSL主要是为了让tengine支持Https的访问请求。 123456cd /usr/local/ wget https://www.openssl.org/source/openssl-fips-2.0.16.tar.gz tar -zxvf openssl-fips-2.0.16 cd openssl-fips-2.0.16./config --prefix=/usr/local/openssl make &amp;&amp; make install 5、gcc yum install gcc gcc-c++ 注：源码的安装一般由3个步骤组成：配置(configure)、编译(make)、安装(make install)。Configure是一个可执行脚本，它有很多选项，在待安装的源码路径下使用命令./configure –help输出详细的选项列表。其中–prefix选项是配置安装的路径，如果不配置该选项，安装后可执行文件默认放在/usr /local/bin，库文件默认放在/usr/local/lib，配置文件默认放在/usr/local/etc，其它的资源文件放在/usr /local/share，比较凌乱。如果配置–prefix，如：./configure –prefix=/usr/local/test，可以把所有资源文件放在/usr/local/test的路径中，不会杂乱。用了—prefix选项的另一个好处是卸载软件或移植软件。当某个安装的软件不再需要时，只须简单的删除该安装目录，就可以把软件卸载得干干净净；移植软件只需拷贝整个目录到另外一个机器即可（相同的操作系统）。当然要卸载程序，也可以在原来的make目录下用一次make uninstall，但前提是make文件指定过uninstall。 以上依赖环境安装后的目录格式如下： 最后进入tengine目录执行： 12345678./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-pcre=/usr/local/pcre-8.42 --with-openssl=/usr/local/openssl --with-zlib=/usr/local/zlib --with-jemalloc=/usr/local/jemalloc make &amp;&amp; make install 由于以上安装过程过于麻烦，笔者使用了简化安装，yum安装依赖环境后，直接执行./configure 123456yum -y install gcc automake autoconf libtool make yum -y install pcre-develyum -y install openssl openssl-devel cd /usr/local/tengine-2.2.3./configuremake &amp;&amp; make install 启动tengine 第一种启动方式会默认加载nginx下的配置文件 ./nginx/sbin/nginx -s reload 第二种启动方式指定tengine的配置文件/usr/local/nginx/sbin/nginx -c /usr/local/tengine-2.2.3/conf/nginx.conf]]></content>
      <categories>
        <category>开源软件</category>
      </categories>
      <tags>
        <tag>Tengine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyCat 配置详解]]></title>
    <url>%2F2018%2F12%2F28%2Fhello-world%2F</url>
    <content type="text"><![CDATA[MyCat是一款基于阿里开源产品Cobar而研发的开源数据库分库分表中间件（基于Java语言开发）。MyCat是一个开源的分布式数据库系统，是一个实现了MySQL协议的服务器，前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。也可以这样理解：数据库是对底层存储文件的抽象，而Mycat是对数据库的抽象。 MyCat关键特性 支持SQL92标准 支持MySQL、Oracle、DB2、SQL Server、PostgreSQL等DB的常见SQL语法 遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理 基于心跳的自动故障切换，支持读写分离，支持MySQL主从，以及galera cluster集群 支持Galera for MySQL集群，Percona Cluster或者MariaDB cluster 基于Nio实现，有效管理线程，解决高并发问题 支持数据的多片自动路由与聚合，支持sum,count,max等常用的聚合函数,支持跨库分页 支持单库内部任意join，支持跨库2表join，甚至基于caltlet的多表join 支持通过全局表，ER关系的分片策略，实现了高效的多表join查询 支持多租户方案 支持分布式事务（弱xa） 支持XA分布式事务（1.6.5） 支持全局序列号，解决分布式下的主键生成问题 分片规则丰富，插件化开发，易于扩展 强大的web，命令行监控 支持前端作为MySQL通用代理，后端JDBC方式支持MySQL、PostgreSQL、Oracle、DB2、SQLServer、MongoDB、巨杉 支持密码加密 支持服务降级 支持IP白名单 支持SQL黑名单、sql注入攻击拦截 支持prepare预编译指令（1.6） 支持非堆内存(Direct Memory)聚合计算（1.6） 支持PostgreSQL的native协议（1.6） 支持mysql和oracle存储过程，out参数、多结果集返回（1.6） 支持zookeeper协调主从切换、zk序列、配置zk化（1.6） 支持库内分表（1.6） 集群基于ZooKeeper管理，在线升级，扩容，智能优化，大数据处理（2.0开发版） MyCat的目标低成本的将现有的单机数据库和应用平滑迁移到“云”端，解决数据存储和业务规模迅速增长情况下的数据瓶颈问题。 MyCat的优势基于阿里开源的Cobar产品而研发，Cobar的稳定性、可靠性、优秀的架构和性能，以及众多成熟的使用案例使得MyCAT一开始就拥有一个很好的起点，站在巨人的肩膀上，能看到更远。 广泛吸取业界优秀的开源项目和创新思路，将其融入到MyCAT的基因中，使得MyCAT在很多方面都领先于目前其他一些同类的开源项目，甚至超越某些商业产品。 MyCAT背后有一只强大的技术团队，其参与者都是5年以上资深软件工程师、架构师、DBA等，优秀的技术团队保证了MyCAT的产品质量。 MyCAT并不依托于任何一个商业公司，因此不像某些开源项目，将一些重要的特性封闭在其商业产品中，使得开源项目成了一个摆设。 MyCat的架构 MyCAT使用MySQL的通讯协议模拟成一个MySQL服务器，并建立了完整的Schema（数据库）、Table （数据表）、User（用户）的逻辑模型，并将这套逻辑模型映射到后端的存储节点DataNode（MySQL Instance）上的真实物理库中，这样一来，所有能使用MySQL的客户端以及编程语言都能将MyCAT当成是MySQLServer来使用，不必开发新的客户端协议。 当MyCAT收到一个客户端发送的SQL请求时，会先对SQL进行语法分析和检查，分析的结果用于SQL路由，SQL路由策略支持传统的基于表格的分片字段方式进行分片，也支持独有的基于数据库E-R关系的分片策略，对于路由到多个数据节点（DataNode）的SQL，则会对收到的数据集进行“归并”然后输出到客户端。SQL执行的过程，简单的说，就是把SQL通过网络协议发送给后端的真正的数据库上进行执行，对于MySQL Server来说，是通过MySQL网络协议发送报文，并解析返回的结果，若SQL不涉及到多个分片节点，则直接返回结果，写入客户端的SOCKET流中，这个过程是非阻塞模式（NIO）。 DataNode是MyCAT的逻辑数据节点，映射到后端的某一个物理数据库的一个Database，为了做到系统高可用，每个DataNode可以配置多个引用地址（DataSource），当主DataSource被检测为不可用时，系统会自动切换到下一个可用的DataSource上，这里的DataSource即可认为是Mysql的主从服务器的地址。 MyCat的初始化 MyCat的逻辑库与任何一个传统的关系型数据库一样，MyCAT也提供了“数据库”的定义，并有用户授权的功能，下面是MyCAT逻辑库相关的一些概念： schema:逻辑库，与MySQL中的Database（数据库）对应，一个逻辑库中定义了所包括的Table。 table：表，即物理数据库中存储的某一张表，与传统数据库不同，这里的表格需要声明其所存储的逻辑数据节点DataNode，这是通过表格的分片规则定义来实现的，table可以定义其所属的“子表(childTable)”，子表的分片依赖于与“父表”的具体分片地址，简单的说，就是属于父表里某一条记录A的子表的所有记录都与A存储在同一个分片上。 分片规则：是一个字段与函数的捆绑定义，根据这个字段的取值来返回所在存储的分片（DataNode）的序号，每个表格可以定义一个分片规则，分片规则可以灵活扩展，默认提供了基于数字的分片规则，字符串的分片规则等。 dataNode: MyCAT的逻辑数据节点，是存放table的具体物理节点，也称之为分片节点，通过DataSource来关联到后端某个具体数据库上，一般来说，为了高可用性，每个DataNode都设置两个DataSource，一主一从，当主节点宕机，系统自动切换到从节点。 dataHost：定义某个物理库的访问地址，用于捆绑到dataNode上。 MyCAT目前通过配置文件的方式来定义逻辑库和相关配置： MYCAT_HOME/conf/schema.xml中定义逻辑库，表、分片节点等内容； MYCAT_HOME/conf/rule.xml中定义分片规则； MYCAT_HOME/conf/server.xml中定义用户以及系统相关变量，如端口等。 MyCat的核心配置解析 schema.xml相关参数说明： &lt;?xml version="1.0"?&gt; &lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt; &lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;!-- 定义一个MyCat的模式，逻辑数据库名称hsg_oa --&gt; &lt;!-- “checkSQLschema”：描述的是当前的连接是否需要检测数据库的模式 --&gt; &lt;!-- “sqlMaxLimit”：表示返回的最大的数据量的行数 --&gt; &lt;!-- “dataNode="dn1"”：该操作使用的数据节点是dn1的逻辑名称 --&gt; &lt;schema name="hsg_oa" checkSQLschema="false" sqlMaxLimit="100" dataNode="dn1"/&gt; &lt;!-- 定义数据的操作节点 --&gt; &lt;!-- “dataHost="localhost1"”：定义数据节点的逻辑名称 --&gt; &lt;!-- “database="mldn"”：定义数据节点要使用的数据库名称 --&gt; &lt;dataNode name="dn1" dataHost="localhost1" database="hsg_oa" /&gt; &lt;!-- 定义数据节点，包括了各种逻辑项的配置 --&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;!-- 配置真实MySQL与MyCat的心跳 --&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- 配置真实的MySQL的连接路径 --&gt; &lt;writeHost host="hostM1" url="192.168.1.128:3306" user="root" password="123456"&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;/mycat:schema&gt; dataHost标签属性说明 balance:负载均衡类型0：不开启读写分离机制，所有读操作都发送到当前可用的writeHost上 1：全部的readHost与stand by writeHost参与select语句的负载均衡， 2：所有读操作都随机在writeHost、readHost上分发 3：所有读请求随机分发到writeHost对应的readHost执行，writeHost不负担读压力 writeType:负载均衡类型 0：所有写操作发送到配置的第一个writeHost，当第一个writeHost宕机时，切换到第二个writeHost，重新启动后以切换后的为准，切换记录在配置文件：dnindex.properties中 1：所有写操作都随发送到配置的writeHost 2：尚未实现 switchType:切换方式 -1：不自动切换1：自动切换（默认） 2：基于MySql主从同步的状态来决定是否切换 server.xml相关参数说明： &lt;!DOCTYPE mycat:server SYSTEM &quot;server.dtd&quot;&gt;&lt;mycat:server xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;system&gt; &lt;!-- 1为开启实时统计、0为关闭 如果使用Mycat-eye监控SQL则需要开启此项--&gt; &lt;code&gt;&lt;property name=&quot;useSqlStat&quot;&gt;0&lt;/property&gt;&lt;/code&gt; &lt;!-- 1为开启全加班一致性检测、0为关闭 --&gt; &lt;property name=&quot;useGlobleTableCheck&quot;&gt;0&lt;/property&gt; &lt;property name=&quot;sequnceHandlerType&quot;&gt;2&lt;/property&gt; &lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--&gt; &lt;property name=&quot;handleDistributedTransactions&quot;&gt;0&lt;/property&gt; &lt;!--off heap for merge/order/group/limit 1开启 0关闭 --&gt; &lt;property name=&quot;useOffHeapForMerge&quot;&gt;1&lt;/property&gt; &lt;!--单位为m--&gt; &lt;property name=&quot;memoryPageSize&quot;&gt;1m&lt;/property&gt; &lt;!--溢出文件缓冲区大小 单位为k--&gt; &lt;property name=&quot;spillsFileBufferSize&quot;&gt;1k&lt;/property&gt; &lt;property name=&quot;useStreamOutput&quot;&gt;0&lt;/property&gt; &lt;!--系统预留内存大小 单位为m--&gt; &lt;property name=&quot;systemReserveMemorySize&quot;&gt;384m&lt;/property&gt; &lt;!--是否采用zookeeper协调切换 --&gt; &lt;property name=&quot;useZKSwitch&quot;&gt;true&lt;/property&gt; &lt;!-- root 登录设置 --&gt; &lt;user name=&quot;root&quot;&gt; &lt;property name=&quot;password&quot;&gt;Hsg@123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;hsg_wx&lt;/property&gt; &lt;!-- 表级 DML 权限设置 --&gt; &lt;!-- &lt;privileges check=&quot;false&quot;&gt; &lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt; &lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt; &lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt; &lt;/schema&gt; &lt;/privileges&gt; --&gt; &lt;/user&gt; &lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;user&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;hsg_wx&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;/user&gt; MyCat常用命令 ./mycat restart 重启服务 ./mycat pause 暂停 ./mycat status 查看启动状态 ./mycat start 启动 ./mycat stop 停止 mysql -uroot -p（账号密码） -h（所在机器IP） -P8066 -D（逻辑库名） 终端登录]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何更高效的管理原生微服务应用]]></title>
    <url>%2F2018%2F12%2F24%2F%E5%A6%82%E4%BD%95%E6%9B%B4%E9%AB%98%E6%95%88%E7%9A%84%E7%AE%A1%E7%90%86%E5%8E%9F%E7%94%9F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[自从阿里重启Dubbo维护以来，其热度迅速蹿升，Github上的星标数已经达到了2.2万个之多，可谓中国开源软件界的明星产品。但是作为自家商业化输出的EDAS产品，却一直以来只能支持闭源的HSF微服务框架，对用户而言不能不说是一种遗憾。虽然以前也是可以支持Dubbo应用的，但却是以一种所谓的Dubbo over HSF来变相实现的，并不是真正无侵入的原生应用。现在这个担忧终于没有了，EDAS官方正式开始了商业化支持Dubbo的进程闲话少絮，我们先来构建一个简单的Dubbo应用，并将其部署到EDAS上面。根据这篇文档介绍的方法，我们来实现一个简单的Echo应用。此应用的能力是客户端通过HTTP接口获得一个字符串消息，然后将此消息发送给服务端，服务端接收到这个消息之后，再原封不动的回传给客户端，最终客户端将此回声信息打印出来，程序结束。 标 题标 题本文并不是一篇教程类文章，因此不会详细介绍该如何编写这样一个应用，只来关注一些重点内容。首先，除了依赖Dubbo库之外，还需要依赖一个EDAS提供的扩展库edas-dubbo-extension。该扩展库就是EDAS支持原生Dubbo应用的关键所在。 图1.edas-dubbo-extension依赖图1.edas-dubbo-extension依赖 除此之外，我们还需要将Dubbo配置文件中的registry参数设置为轻量级配置中心的地址。 标 注 按图 2.registry地址图2.registry地址 经过了这样的修改之后，我们的应用就可以原封不动的部署到EDAS上面了。 实际的部署过程与普通应用无异，应该是EDAS会自动判断该应用是否为原生Dubbo进而区分对待，因此熟悉EDAS的用户在这一点上不会碰到任何问题。部署完成以后在Provider和Consumer应用的服务列表里面，分别可以看到如下内容，说明服务启动正常。]]></content>
      <categories>
        <category>互联网</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo部署到Github服务器]]></title>
    <url>%2F2018%2F12%2F24%2Fnew-Day%2F</url>
    <content type="text"><![CDATA[Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。正常来说，不需要部署到我们的服务器上，我们的服务器上保存的，其实是基于在hexo通过markdown编写的文章，然后hexo帮我们生成静态的html页面，然后，将生成的html上传到我们的服务器。为了更加方便的实现本地到git服务器的部署同步问题，因此可以通过如下操作配置实现本地编写文章后，直接部署到Github服务器，通过Github域名来访问,达到快捷、高效、一劳永逸的效果。 配置文件修改_config.yml文件中对应的repo值如下 1234deploy:type: gitrepository: git@github.com:yangzhiwen911/yangzhiwen911.github.io.gitbranch: master 注：repository的值 即为github项目中的ssh地址，直接复制过来即可。 生成SSH git bash中配置name(git的用户名)和email（git的邮箱） 12git config --global user.name "yourname"git config --global user.email "youremail" 进入~目录，执行ssh-keygen，生成.ssh文件夹会有一对公钥和私钥,复制公钥内容到Github 1ssh-keygen -t rsa -C "youremail" #生成ssh对应key，直接输入回车并设置密码即可。 Github对应的ssh and key地址入口： 在gitbash中，查看是否成功 1ssh -T git@github.com 当出现你的Github用户名的时候，即为成功，可以进行下一步操作。 安装插件 在生成以及部署文章之前，需要安装一个插件，这样才能用命令部署到GitHub。 1npm install hexo-deployer-git --save 最后执行部署： 12hexo dhexo s 至此，部署过程结束，可以直接通过http://yourname.github.io 网址查看你的个人博客了！ 部署问题 如果出现缺少模块等报错问题，直接使用hexo install 下载命令即可。 如果出现模板渲染等报错问题，需检查md文件是否有标签未闭合等语法问题。 命令大全 Hexo常用命令： 12345678910hexo new "postName" #新建文章hexo new page "pageName" #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）hexo deploy #将.deploy目录部署到GitHubhexo version #查看hexo版本号hexo --debug #调试模式，输出所有日志信息hexo --safe #安全模式，禁用所有的插件和脚本hexo --silent #无日志输出模式hexo --config config-path #指定配置文件，代替默认的_config.yml Hexo缩略语： 12345hexo n == hexo new #创建一个新的blog页面hexo g == hexo generate #生成静态文件hexo s == hexo server #启动本地服务器hexo d == hexo deploy #部署网站项目hexo v == hexo version #hexo版本 Hexo复合命令： 1234hexo deploy -ghexo server -ghexo server -d (hexo s ) #启动本地服务器hexo generate -w #watch参数的缩写，source/_post中的md文件有改动，就会自动publish Hexo清除命令： 1hexo clean 注：Hexo原理就是hexo在执行hexo generate时会在本地先把博客生成的一套静态站点放到public文件夹中，在执行hexo deploy时将其复制到.deploy文件夹中。Github的版本库通常建议同时附上README.md说明文件，但是hexo默认情况下会把所有md文件解析成html文件，所以即使你在线生成了README.md，它也会在你下一次部署时被删去。怎么解决呢？在执行hexo deploy前把在本地写好的README.md文件复制到.deploy文件夹中，再去执行hexo deploy。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>MyCat</tag>
        <tag>Github</tag>
        <tag>ssh</tag>
        <tag>rsa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java技术栈梳理分享]]></title>
    <url>%2F2018%2F12%2F24%2FJackie-Yang%2F</url>
    <content type="text"><![CDATA[Java面试分析 结合底层实现原理梳理了一些面试点：]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
</search>
